{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring the ID Space mapping to the streaming services because we are not using it\n",
    "# df_track_id_space = pd.read_csv('download/track_id_space.csv', sep=';')\n",
    "# df_album_id_space = pd.read_csv('download/album_id_space.csv', sep=';')\n",
    "# df_artist_id_space = pd.read_csv('download/artist_id_space.csv', sep=';')\n",
    "\n",
    "# Tracks\n",
    "df_track = pd.read_csv('download/track.csv', sep=';')\n",
    "df_album_track = pd.read_csv('download/album_track.csv', sep=';')\n",
    "df_artist_track = pd.read_csv('download/artist_track.csv', sep=';')\n",
    "df_track_sim = pd.read_csv('download/track_similarity.csv', sep=';')\n",
    "\n",
    "# Albums and Artists\n",
    "df_album = pd.read_csv('download/album.csv', sep=';')\n",
    "df_artist_album = pd.read_csv('download/artist_album.csv', sep=';')\n",
    "df_artist = pd.read_csv('download/artist.csv', sep=';')\n",
    "\n",
    "# Ratings\n",
    "df_lastfm_rating = pd.read_csv('download/lastfm_rating.csv', sep=';')\n",
    "df_billboard_rating = pd.read_csv('download/billboard_rating.csv', sep=';')\n",
    "df_spotify_rating = pd.read_csv('download/spotify_rating.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_track.shape)\n",
    "print(df_album_track.shape)\n",
    "\n",
    "# Add information about the album to the track\n",
    "df_track = pd.merge(df_track, df_album_track, on='track_id', how='left')\n",
    "\n",
    "df_track = df_track.drop(columns=['position']) # Useless to know the position of the track in the album\n",
    "\n",
    "print(df_track.shape)\n",
    "\n",
    "df_track.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_track.shape)\n",
    "print(df_album.shape)\n",
    "\n",
    "# add to track the column artist_id\n",
    "df_track = pd.merge(df_track, df_artist_track, on='track_id', how='left')\n",
    "\n",
    "# replace \"title\" by \"name\"\n",
    "df_track = df_track.rename(columns={'title': 'name'})\n",
    "\n",
    "print(df_track.shape)\n",
    "\n",
    "df_track.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df_track.to_csv('data/track.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_album.shape)\n",
    "print(df_artist_album.shape)\n",
    "\n",
    "# Add information about the artist to the album\n",
    "df_album = pd.merge(df_album, df_artist_album, on='album_id')\n",
    "\n",
    "print(df_album.shape)\n",
    "\n",
    "df_album.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df_album.to_csv('data/album.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_artist.shape)\n",
    "\n",
    "df_artist = df_artist.drop(columns=['image_url'])\n",
    "\n",
    "df_artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tracks_by_artist(artist_id, only_id=False):\n",
    "    return df_track[df_track['artist_id'] == artist_id] if not only_id else df_track[df_track['artist_id'] == artist_id]['track_id']\n",
    "\n",
    "def get_all_albums_by_artist(artist_id, only_id=False):\n",
    "    return df_album[df_album['artist_id'] == artist_id] if not only_id else df_album[df_album['artist_id'] == artist_id]['album_id']\n",
    "\n",
    "# Add the new columns \"all_tracks\" and \"all_albums\" to the artist as a list of ids\n",
    "df_artist['all_tracks'] = df_artist['artist_id'].apply(lambda x: get_all_tracks_by_artist(x, True).tolist())\n",
    "df_artist['all_albums'] = df_artist['artist_id'].apply(lambda x: get_all_albums_by_artist(x, True).tolist())\n",
    "\n",
    "df_artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df_artist.to_csv('data/artist.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove from sim the column source because it does not have information\n",
    "df_track_sim = df_track_sim.drop(columns=['source', 'id'])\n",
    "\n",
    "# rename track_id to track_id_1 and similar_track_id to track_id_2\n",
    "df_track_sim.rename(columns={'track_id': 'track_id_1', 'similar_track_id': 'track_id_2'}, inplace=True)\n",
    "\n",
    "df_track_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df_track_sim.to_csv('data/track_similarity.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_lastfm_rating.shape)\n",
    "df_lastfm_rating = df_lastfm_rating.drop(columns=['id'])\n",
    "df_lastfm_rating['date_lastfm'] = df_lastfm_rating['date_lastfm'].str.replace(' 00:00:00', '')\n",
    "df_lastfm_rating['date_lastfm'] = pd.to_datetime(df_lastfm_rating['date_lastfm'])\n",
    "\n",
    "df_lastfm_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_billboard_rating.shape)\n",
    "df_billboard_rating = df_billboard_rating.drop(columns=['id'])\n",
    "df_billboard_rating['date_billboard'] = df_billboard_rating['date_billboard'].str.replace(' 00:00:00', '')\n",
    "df_billboard_rating['date_billboard'] = pd.to_datetime(df_billboard_rating['date_billboard'])\n",
    "\n",
    "df_billboard_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_spotify_rating.shape)\n",
    "df_spotify_rating = df_spotify_rating.drop(columns=['id'])\n",
    "df_spotify_rating['date_spotify'] = df_spotify_rating['date_spotify'].str.replace(' 00:00:00', '')\n",
    "df_spotify_rating['date_spotify'] = pd.to_datetime(df_spotify_rating['date_spotify'])\n",
    "\n",
    "df_spotify_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the entries for track_id == 428 from lastfm\n",
    "print(df_lastfm_rating[df_lastfm_rating['track_id'] == 428].shape)\n",
    "df_lastfm_rating[df_lastfm_rating['track_id'] == 428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the entries for track_id == 428 from billboard\n",
    "print(df_billboard_rating[df_billboard_rating['track_id'] == 428].shape)\n",
    "df_billboard_rating[df_billboard_rating['track_id'] == 428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the entries for track_id == 428 from spotify\n",
    "print(df_spotify_rating[df_spotify_rating['track_id'] == 428].shape)\n",
    "df_spotify_rating[df_spotify_rating['track_id'] == 428]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lastfm_rating['time_epoch'] = df_lastfm_rating['date_lastfm'].astype(np.int64) // 10**9\n",
    "df_billboard_rating['time_epoch'] = df_billboard_rating['date_billboard'].astype(np.int64) // 10**9\n",
    "df_spotify_rating['time_epoch'] = df_spotify_rating['date_spotify'].astype(np.int64) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get smallest and largest date from all ratings\n",
    "min_date = min(df_lastfm_rating['date_lastfm'].min(), df_billboard_rating['date_billboard'].min(), df_spotify_rating['date_spotify'].min())\n",
    "max_date = max(df_lastfm_rating['date_lastfm'].max(), df_billboard_rating['date_billboard'].max(), df_spotify_rating['date_spotify'].max())\n",
    "print(min_date, max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get smallest and largest epoch from all ratings\n",
    "min_epoch = min(df_lastfm_rating['time_epoch'].min(), df_billboard_rating['time_epoch'].min(), df_spotify_rating['time_epoch'].min())\n",
    "max_epoch = max(df_lastfm_rating['time_epoch'].max(), df_billboard_rating['time_epoch'].max(), df_spotify_rating['time_epoch'].max())\n",
    "\n",
    "print(min_epoch, max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all epochs to weekly epochs\n",
    "week = 7 * 24 * 60 * 60\n",
    "df_lastfm_rating['time_epoch'] = ((((df_lastfm_rating['time_epoch']) // week) * week - 259200)-1072656000) / week\n",
    "df_billboard_rating['time_epoch'] = ((((df_billboard_rating['time_epoch']) // week) * week - 259200)-1072656000) / week\n",
    "df_spotify_rating['time_epoch'] = ((((df_spotify_rating['time_epoch']) // week) * week - 259200)-1072656000) / week\n",
    "\n",
    "# print two epochs to see if it is working\n",
    "print(df_lastfm_rating['time_epoch'].head(2))\n",
    "print(df_billboard_rating['time_epoch'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique track_ids and time_epochs from the ratings\n",
    "unique_track_ids = pd.concat([df_lastfm_rating['track_id'], df_billboard_rating['track_id'], df_spotify_rating['track_id']]).unique()\n",
    "unique_time_epochs = pd.concat([df_lastfm_rating['time_epoch'], df_billboard_rating['time_epoch'], df_spotify_rating['time_epoch']]).unique()\n",
    "\n",
    "# Create a MultiIndex from the product of unique track_ids and time_epochs, sort by time_epoch\n",
    "multi_index = pd.MultiIndex.from_product([unique_track_ids, unique_time_epochs], names=['track_id', 'time_epoch']).sort_values()\n",
    "# Create a dataframe from the MultiIndex\n",
    "df_combinations = pd.DataFrame(index=multi_index).reset_index()\n",
    "\n",
    "print(df_combinations.shape)\n",
    "df_combinations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_combinations with each rating DataFrame\n",
    "df_combined = df_combinations.merge(df_lastfm_rating[['track_id', 'time_epoch', 'position_lastfm', 'no_of_listeners_lastfm']],\n",
    "                                    on=['track_id', 'time_epoch'], how='left')\n",
    "\n",
    "df_combined = df_combined.merge(df_spotify_rating[['track_id', 'time_epoch', 'position_spotify', 'no_of_listeners_spotify']],\n",
    "                                on=['track_id', 'time_epoch'], how='left')\n",
    "\n",
    "df_combined = df_combined.merge(df_billboard_rating[['track_id', 'time_epoch', 'position_billboard']],\n",
    "                                on=['track_id', 'time_epoch'], how='left')\n",
    "print(df_combined.shape)\n",
    "# Rename if necessary or just work with the merged DataFrame\n",
    "df_combined = df_combined.dropna(subset=['position_lastfm', 'position_spotify', 'position_billboard'], how='all')\n",
    "\n",
    "print(df_combined.shape)\n",
    "df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df_combined.to_csv('data/weekly_rating.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all unique dates\n",
    "start_date = pd.to_datetime(\"2004-01-01\")\n",
    "end_date = pd.to_datetime(\"2015-02-01\")\n",
    "all_dates = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "print('Number of unique dates:', len(all_dates))\n",
    "print('First date:', min(all_dates))\n",
    "print('Last date:', max(all_dates))\n",
    "\n",
    "# for each date, add a row for each track__id\n",
    "ids = df_track['track_id'].unique() # unique track ids\n",
    "dates = all_dates # unique dates\n",
    "print('Number of unique track ids:', len(ids))\n",
    "\n",
    "# Create a unified date DataFrame for all dates and all track ids combinations\n",
    "date_df = pd.DataFrame()\n",
    "date_df['track_id'] = np.repeat(ids, len(dates))\n",
    "date_df['date'] = np.tile(dates, len(ids))\n",
    "date_df['date'] = pd.to_datetime(date_df['date'])\n",
    "print(date_df.shape)\n",
    "date_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_service_data(service_df, date_df, date_col):\n",
    "    service_df[date_col] = pd.to_datetime(service_df[date_col])\n",
    "    service_df = service_df.dropna(subset=[date_col])\n",
    "    service_df = service_df.rename(columns={date_col: 'date'})\n",
    "    service_df = service_df.sort_values(by='date').reset_index(drop=True)\n",
    "    return pd.merge(date_df, service_df, on=['date', 'track_id'], how='left')\n",
    "\n",
    "date_df = align_service_data(df_lastfm_rating, date_df, 'date_lastfm')\n",
    "date_df = align_service_data(df_spotify_rating, date_df, 'date_spotify')\n",
    "date_df = align_service_data(df_billboard_rating, date_df, 'date_billboard')\n",
    "print(date_df.shape)\n",
    "\n",
    "# if a row has nan in all 3 position_lastfm, position_spotify and position_billboard, then drop it\n",
    "date_df = date_df.dropna(subset=['position_lastfm', 'position_spotify', 'position_billboard'], how='all')\n",
    "print(date_df.shape)\n",
    "\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "date_df.to_csv('data/rating.csv', index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
